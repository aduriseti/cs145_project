{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from GetOldTweets import got\n",
    "\n",
    "consumer_keys = [\"51MI8RrYmzO4btCKG4Qb5uqAa\", \"glUJXqMWks3Hlu1QgPa2KvMHA\"]\n",
    "consumer_secrets = [\"ajpPv3Ag0NvMEQLBIwiPyDyU78BbLZn8IS1gTba4x9ZOHNPMNM\", \"lDjQ3F9OraljWas6koMqYKzP9fFu6wdNiBEoBbvQUkNmr304Q1\"]\n",
    "access_tokens = [\"3004471069-VDbNpT9NO0QOtiqKZXkoH5Flv4MArCflIYImXjn\", \"905545734748905472-1427NPHJ3VOgSxhygcK6gVNFTZgu4AE\"]\n",
    "access_tokens_secret = [\"sP6KMjPZXxYAnaae8bOiauLjCVnx8bzWkBk4KU1iZBxdl\", \"vFrkF37p0B4C4cYiwMWhAHCiKj2r0wCrKcfutaWzg79fB\"]\n",
    "\n",
    "consumer_key = consumer_keys[1]\n",
    "consumer_secret = consumer_secrets[1]\n",
    "access_token = access_tokens[1]\n",
    "access_token_secret = access_tokens_secret[1]\n",
    "\n",
    "# Creating the authentication object\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "# Setting your access token and secret\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "# Creating the API object while passing in auth information\n",
    "api = tweepy.API(auth) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def printTweets(tweets):\n",
    "    print(\"# tweets is: \"+str(len(tweets)))\n",
    "    counter = 0\n",
    "    for tweet in tweets:\n",
    "        print(str(counter)+\": \" + tweet.text)\n",
    "\n",
    "\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def printDateText(tweets):\n",
    "    print(\"# tweets is: \"+str(len(tweets)))\n",
    "    counter = 0\n",
    "    for tweet in tweets:\n",
    "        print(str(counter)+\": \" + str(tweet.date)+\"  ||  \" + tweet.text)\n",
    "\n",
    "\n",
    "\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getSortCriteria(tweet):\n",
    "    print(tweet)\n",
    "    return tweet.date\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def writeToFile(path, tweets, language=None):\n",
    "    output = open(\"tweettext.txt\", \"wb\")\n",
    "    counter = 0\n",
    "\n",
    "    for tweet in new_tweets[:n]:\n",
    "        # printing the text stored inside the tweet object\n",
    "    #    print(tweet.user.screen_name,\"Tweeted:\",tweet.text)\n",
    "        if (language == None) or (language == tweet.lang):\n",
    "            adjusted_tweet = (tweet.text).encode('utf-8')\n",
    "\n",
    "            output.write(adjusted_tweet)\n",
    "            print(str(counter)+adjusted_tweet)\n",
    "            output.write(\"\\n\")\n",
    "\n",
    "            print(tweet.created_at)\n",
    "\n",
    "            counter += 1\n",
    "            \n",
    "  \n",
    "    output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib2\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "#https://finance.yahoo.com/quote/AMZN\n",
    "    \n",
    "def get_historical_data(name, number_of_days):\n",
    "    data = []\n",
    "    url = \"https://finance.yahoo.com/quote/\" + name + \"/history?period1=946713600&period2=1510732800&interval=1d&filter=history&frequency=1d/\"\n",
    "    rows = bs(urllib2.urlopen(url).read()).findAll('table')[0].tbody.findAll('tr')\n",
    "\n",
    "    for each_row in rows:\n",
    "        divs = each_row.findAll('td')\n",
    "        if divs[1].span.text  != 'Dividend': #Ignore this row in the table\n",
    "            #I'm only interested in 'Open' price; For other values, play with divs[1 - 5]\n",
    "            data.append({'Date': divs[0].span.text, 'Open': float(divs[1].span.text.replace(',',''))})\n",
    "\n",
    "    return data[number_of_days:number_of_days+1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "\n",
    "def getPriceFromCSV(filepath, date):\n",
    "    with open(filepath, 'rt') as f:\n",
    "        #skip header\n",
    "        next(f)\n",
    "        \n",
    "        reader = csv.reader(f)\n",
    "        rownum = 1\n",
    "        for row in reader: \n",
    "            rownum += 1\n",
    "\n",
    "            \n",
    "            #CSV appears to be in mm/dd/yyyy format but parsing is yyyy/mm/dd ? weird\n",
    "            adjusted_date = (dt.datetime.strptime(str(row[0]), '%Y-%m-%d')).date()\n",
    "\n",
    "            if adjusted_date == date:\n",
    "                print(\"price of interest is: \")\n",
    "                print((str(row[1]), str(row[2]), str(row[3]), str(row[4]), str(row[5])) )\n",
    "                return [str(row[1]), str(row[2]), str(row[3]), str(row[4]), str(row[5])]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#returns filtered tweets\n",
    "def filterTweets(tweets, remove_duplicates=True):\n",
    "    combined_tweets = tweets\n",
    "    if remove_duplicates: \n",
    "        combined_tweets = list(set(combined_tweets)) #remove duplicates\n",
    "        \n",
    "    counter = 0\n",
    "    for tweet in combined_tweets:\n",
    "    #    print(counter)\n",
    "        try:\n",
    "            if tweet.date:\n",
    "                counter += 1\n",
    "                continue\n",
    "        except AttributeError:\n",
    "            print(\"exception on number: \" + str(counter))\n",
    "            print(tweet.text)\n",
    "           # combined_tweets.remove(tweet)\n",
    "            combined_tweets = list(filter(lambda twt: twt != tweet, combined_tweets))\n",
    "\n",
    "            counter += 1\n",
    "\n",
    "    print(\"filtered: \" + str(counter) )      \n",
    "#    printDateText(combined_tweets)\n",
    "    return combined_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pulling tweets...\n",
      "3953\n",
      "# tweets is: 0\n",
      "processing day: 2007-01-03\n",
      "tweets size: 0\n",
      "# tweets is: 0\n",
      "processing day: 2007-01-04\n",
      "tweets size: 0\n",
      "# tweets is: 0\n",
      "processing day: 2007-01-05\n",
      "tweets size: 0\n",
      "# tweets is: 0\n",
      "processing day: 2007-01-06\n",
      "tweets size: 0\n",
      "# tweets is: 0\n",
      "processing day: 2007-01-07\n",
      "tweets size: 0\n",
      "Twitter weird response. Try to see on browser: https://twitter.com/search?q=%20AMZN%20since%3A2007-01-08%20until%3A2007-01-09&src=typd\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from yahoo_finance import Share\n",
    "import datetime as dt\n",
    "from datetime import timedelta\n",
    "import os\n",
    "\n",
    "remove_duplicates = True\n",
    "stock_ticker = \"AMZN\"\n",
    "query = \"AMZN\"\n",
    "max_tweets = 10000\n",
    "n = max_tweets\n",
    "\n",
    "#twitter was founded in 2006. Start in 2007 for safety\n",
    "base_date = \"2007-01-03\"\n",
    "start_date = \"2007-01-04\"\n",
    "end_date = \"2017-10-31\"\n",
    "\n",
    "#new_tweets = [tweet for tweet in tweepy.Cursor(api.search, \n",
    "                                   #        q=query).items(max_tweets)]\n",
    "\n",
    "print(\"Pulling tweets...\")    \n",
    "#get old tweets\n",
    "\n",
    "base_date_dt = dt.datetime.strptime(base_date, '%Y-%m-%d')\n",
    "start_date_dt = dt.datetime.strptime(start_date, '%Y-%m-%d')\n",
    "end_date_dt = dt.datetime.strptime(end_date, '%Y-%m-%d')\n",
    "delta = end_date_dt - start_date_dt\n",
    "\n",
    "num_days = int(delta.days)\n",
    "print(num_days)\n",
    "begin = base_date_dt.strftime('%Y-%m-%d')\n",
    "\n",
    "i = 1\n",
    "tweets = []\n",
    "processed_tweets = []\n",
    "\n",
    "path = os.getcwd()+\"/\"\n",
    "f = open(path+'tweets_'+stock_ticker+'.txt', 'a')    \n",
    "f2 = open(path+'labels_'+stock_ticker+'.txt', 'a')\n",
    "#perform data structure swapping and clearing to save memory for large runs\n",
    "for single_date in (start_date_dt + timedelta(n) for n in range(num_days-1)):\n",
    "    date_only = single_date.strftime('%Y-%m-%d')\n",
    "    \n",
    "    end = single_date.strftime('%Y-%m-%d')\n",
    "\n",
    "    tweetCriteria = got.manager.TweetCriteria().setQuerySearch(query).setSince(begin).setUntil(end).setMaxTweets(max_tweets)\n",
    "    tweets.extend(got.manager.TweetManager.getTweets(tweetCriteria))#[0]\n",
    "    \n",
    "    printTweets(tweets)\n",
    "    print(\"processing day: \" + begin)\n",
    "    print(\"tweets size: \" + str(len(tweets)))\n",
    "    \n",
    "    #filter the sets of tweets in batches of 20\n",
    "    if ((i % 20) == 0) or ((num_days - i) < 20):\n",
    "        processed_tweets.extend(filterTweets(tweets, remove_duplicates=True))\n",
    "        tweets = []\n",
    "        \n",
    "        #sort by date\n",
    "        processed_tweets.sort(key=getSortCriteria)\n",
    "        #printDateText(combined_tweets)\n",
    "\n",
    "\n",
    "        #find associated stock prices\n",
    "        #stock = Share( stock_ticker )\n",
    "        cur_date = dt.datetime.now()\n",
    "        print(cur_date)\n",
    "\n",
    "        tweet_labels = []\n",
    "        cutoff_date = dt.datetime.strptime(\"2017-10-30\", '%Y-%m-%d')\n",
    "\n",
    "\n",
    "        datapath = os.getcwd()+\"/StockData/\"+stock_ticker+\".csv\"\n",
    "        cutoff_threshold = timedelta(days=0)\n",
    "\n",
    "        for tweet in processed_tweets:\n",
    "            tweet_date = tweet.date\n",
    "            print(\"tweet date is: \" + str(tweet_date) +\" of type: \" + str(type(tweet_date)))\n",
    "\n",
    "            #pull from file since the tweet is too old\n",
    "           # if (tweet_date - cutoff_date) < cutoff_threshold:\n",
    "            tweet_dateOnly = (tweet_date).date()\n",
    "            price = getPriceFromCSV(datapath, tweet_dateOnly)\n",
    "            if(price == None): #could have been a holiday\n",
    "                #processed_tweets.remove(tweet)\n",
    "                processed_tweets = list(filter(lambda twt: twt != tweet, processed_tweets))\n",
    "\n",
    "\n",
    "            else:\n",
    "                tweet_labels.append(price)\n",
    "                #            print(\"type is: \" + str(type(open_price)))\n",
    "\n",
    "            \"\"\"\n",
    "                    \n",
    "            else:\n",
    "                delta = cur_date - tweet_date\n",
    "                delta_days = delta.days\n",
    "                print(\"delta days: \"+str(delta_days))\n",
    "\n",
    "                price = get_historical_data(stock_ticker, delta_days)\n",
    "                tweet_labels.extend(str(price))\n",
    "                \"\"\"\n",
    "        #test\n",
    "        #print(get_historical_data(stock_ticker, 10))\n",
    "\n",
    "\n",
    "        #print(counter)    \n",
    "        #printDateText(processed_tweets)\n",
    "\n",
    "        #dump to file\n",
    "        for t in processed_tweets:\n",
    "            f.write(((t.date).strftime('%Y-%m-%d')) + \",  \" + (t.text).encode('utf-8'))\n",
    "            f.write('\\n')\n",
    "\n",
    "        for price in tweet_labels:\n",
    "            print(\"iterating through price\")\n",
    "            print(price)\n",
    "#            print(str(price[0])+',' + str(price[1])+',' + str(price[2])+',' + str(price[3])+',' + str(price[4]))\n",
    "            f2.write(str(price[0])+',' + str(price[1])+',' + str(price[2])+',' + str(price[3])+',' + str(price[4]))\n",
    "            f2.write('\\n')\n",
    "\n",
    "        processed_tweets = []\n",
    "\n",
    "\n",
    "#    printTweets(old_tweets)\n",
    "    \n",
    "    #set new begin to be the current day for the next iteration\n",
    "    begin = end\n",
    "    \n",
    "    i+=1\n",
    "\n",
    "f.close()\n",
    "f2.close()\n",
    "      \n",
    "\n",
    "\n",
    "lines_in_tweets = 0\n",
    "f = open(path+'tweets_'+stock_ticker+'.txt', 'r')\n",
    "for line in f:\n",
    "    lines_in_tweets += 1\n",
    "    \n",
    "f.close()\n",
    "\n",
    "lines_in_labels = 0\n",
    "f2 = open(path+'labels_'+stock_ticker+'.txt', 'r')\n",
    "for line in f2:\n",
    "    lines_in_labels += 1\n",
    "    \n",
    "print(\"#lines text: \" + str(lines_in_tweets) +\"  #lines labels: \" + str(lines_in_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
